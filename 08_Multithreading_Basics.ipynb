{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Julia only using a single thread. To start it with multiple threads we must tell it explicitly:\n",
    "\n",
    "##### Command line argument\n",
    "\n",
    "```bash\n",
    "julia -t 4\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "julia --threads 4\n",
    "```\n",
    "\n",
    "##### Environmental variable\n",
    "\n",
    "On Linux/MacOS:\n",
    "\n",
    "```bash\n",
    "export JULIA_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "On Windows:\n",
    "\n",
    "```bash\n",
    "set JULIA_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "Afterwards start julia *in the same terminal*.\n",
    "\n",
    "##### Jupyter kernel\n",
    "\n",
    "You can also create a *Jupyter kernel* for multithreaded Julia:\n",
    "\n",
    "```julia\n",
    "using IJulia\n",
    "installkernel(\"Julia (4 threads)\", \"--project=@.\", env=Dict(\"JULIA_NUM_THREADS\"=>\"4\"))\n",
    "```\n",
    "\n",
    "*Note:* This has to be manually redone for every new Julia version and you have to restart your Jupyter process to see an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check this has worked we we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Threads.@spawn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Threads.@spawn` macro dynamically spawns a new thread to execute a command in the background. Programmatically, it creates a `Task` and puts it on the todo-list. Whenever a thread is free, the task is dynamically assigned to a thread and executing the work starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.@spawn println(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** `Threads.@spawn` returns the created task *immediately*, but we might have to wait until the task is done and fetch the result later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Threads.@spawn begin\n",
    "    sleep(3)\n",
    "    4\n",
    "end\n",
    "# We immediately get here\n",
    "@time fetch(t)  # This waits until the task is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent the immediate return, we need to explicitly synchronise the execution using an `@sync` macro barrier.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync begin\n",
    "    t = Threads.@spawn begin\n",
    "        sleep(3)\n",
    "        4\n",
    "    end\n",
    "end\n",
    "\n",
    "@time fetch(t)  # No need to wait, the task is already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling an array in parallel\n",
    "\n",
    "Now, let's use this to actually parallelise something: We will fill an array in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fill_array_parallel(a)\n",
    "    @sync for i in 1:length(a)\n",
    "        Threads.@spawn a[i] = Threads.threadid()\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = zeros(Threads.nthreads()*10);\n",
    "fill_array_parallel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show count(a .== 1.0)\n",
    "@show count(a .== 2.0)\n",
    "@show count(a .== 3.0)\n",
    "@show count(a .== 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Due to the **dynamic scheduling** some threads actually do more work (more values of i) than others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting threading\n",
    "\n",
    "A key motion in the Julia ecosystem is to support **nested threading**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function threaded_fun()\n",
    "    x = Threads.threadid()\n",
    "    Threads.@spawn println(\"job1\", \" (spawned from $x, processed by $(Threads.threadid()))\")\n",
    "    Threads.@spawn println(\"job2\", \" (spawned from $x, processed by $(Threads.threadid()))\")\n",
    "    Threads.@spawn println(\"job3\", \" (spawned from $x, processed by $(Threads.threadid()))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync for i in 1:Threads.nthreads()\n",
    "    Threads.@spawn threaded_fun()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key point about this is that in this way the threading of different layers of functions does not interfer by causing more threads to be spawned than there are workers (CPU cores).\n",
    "\n",
    "The issue happens rather easily whenever a parallelised routine like `threaded_fun` (e.g. a numerical integration routine) is again called from a parallelised outer loop (e.g. a solver). To avoid the problem one needs to introduce some kind of coupling between the routines to communicate to the inner routine (`threaded_fun`) how many threads it may use. To avoid the need to do this explicitly, Julia implemented has decided to base its threading mostly on dynamic scheduling and the `@spawn` formalism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threading takes extra care: Parallel summation\n",
    "\n",
    "We consider the case of a parallel summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum(xs)\n",
    "    s = zero(eltype(xs))\n",
    "    for x in xs\n",
    "        s += x\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum_parallel_naive(xs)\n",
    "    s = zero(eltype(xs))\n",
    "    @sync for x in xs\n",
    "        Threads.@spawn (s += x)\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = rand(100_000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show sum(xs);\n",
    "@show mysum(xs);\n",
    "@show mysum_parallel_naive(xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm ... the problem is a so-called **race condition**, a clash due to the parallel writing access from multiple threads.\n",
    "\n",
    "One way to solve this is by using [Atomic Operations](https://docs.julialang.org/en/v1/manual/multi-threading/#Atomic-Operations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base.Threads: Atomic, atomic_add!\n",
    "\n",
    "function mysum_parallel_atomics(xs)\n",
    "    T = eltype(xs)\n",
    "    s = Atomic{T}(zero(T))\n",
    "    @sync for x in xs\n",
    "        Threads.@spawn atomic_add!(s, x)\n",
    "    end\n",
    "    s[]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show mysum(xs);\n",
    "@show mysum_parallel_atomics(xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mysum($xs);\n",
    "@btime mysum_parallel_atomics($xs);\n",
    "@btime mysum_parallel_naive($xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Atomics are generally bad. Don't use this paradigm in production unless you know what you are doing. Use FLoops.jl (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there no static scheduling option in Julia?\n",
    "\n",
    "Yes there is and it can sometimes be faster than dynamic threading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum_parallel_threads(xs)\n",
    "    T = eltype(xs)\n",
    "    s = Atomic{T}(zero(T))\n",
    "    Threads.@threads :static for x in xs\n",
    "        atomic_add!(s, x)\n",
    "    end\n",
    "    s[]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mysum_parallel_atomics($xs);\n",
    "@btime mysum_parallel_threads($xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While on a first look this has advantages in form of a 10-fold reduced speed, the disadvantages are that there is no nested threading and there can be severe load imbalancing since work is split statically at startup of the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLoops.jl: Easy and fast dynamic threads\n",
    "\n",
    "As a way out the Julia ecosystem has brought forward a number of carefully optimised packages for threaded execution based on *dynamic* scheduling. One example is [FLoops.jl](https://github.com/JuliaFolds/FLoops.jl). Our `mysum` function is parallelised using FLoops by just adding two macros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using FLoops\n",
    "\n",
    "function mysum_parallel_floops(xs)\n",
    "    s = zero(eltype(xs))\n",
    "    @floop for x in xs\n",
    "        @reduce s += x\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still it gives the right result and is faster than our statically scheduled `@threads` version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show mysum(xs);\n",
    "@show mysum_parallel_floops(xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime mysum_parallel_threads($xs);\n",
    "@btime mysum_parallel_floops($xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The fact that `FLoops` is faster is a little misleading at first sight, but illustrates an important point nevertheless:\n",
    "\n",
    "- If *perfectly* written *statically scheduled* threads are faster than dynamically scheduled threads\n",
    "- But this requires deep insight to obtain optimal load balancing, careful use of atomics etc.\n",
    "- If you are not a parallelisation expert carefully optimised packages based on *dynamical scheduling* will likely be faster for your use case. The plain reason is that the *learning time* to understand all the neccessary tricks and the time needed to *fix all the subtle bugs* is not to be underestimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "- Julia's thread infrastructure is mostly based on *dynamic* threading\n",
    "- The advantages are thread nesting and better load balancing in cases where load per iteration is not uniform.\n",
    "- The disadvantage is a larger startup time per thread\n",
    "- Packages like FLoops.jl make it easy to write fast parallel code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More details\n",
    "- https://juliafolds.github.io/data-parallelism/"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.7.2",
   "language": "julia",
   "name": "julia-(4-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
